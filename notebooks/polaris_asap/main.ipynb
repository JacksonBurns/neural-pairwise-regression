{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `nepare` ASAP `polaris` Competition\n",
    "\n",
    "This notebook demonstrates using Neural Pairwise Regression (via `nepare`) with the `polaris` benchmarking library to compete in the ASAP discovery competition.\n",
    "\n",
    "See the `meta` directory in the `nepare` repository for some more theoretical exploration of what this notebook does.\n",
    "\n",
    "Files in the `utils` subdirectory contain inline comments explaining what the various convenience functions do.\n",
    "\n",
    "## Requirements\n",
    "This should work on Python 3.10 or newer - I ran with 3.12\n",
    "\n",
    "The following dependencies are required:\n",
    " - polaris-lib >=0.11.6\n",
    " - pandas\n",
    " - rdkit\n",
    " - lightning\n",
    " - torch\n",
    " - fastprop\n",
    " - mordredcommunity\n",
    " - chemprop ~2.1\n",
    " - ipywidgets\n",
    "\n",
    "You will also need to run `pip install .` in the repository's root directory to install `nepare`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `polaris` Setup\n",
    "\n",
    "After running `polaris login` on the command line, we can import everything (checking that the version is recent enough) and then download the benchmark data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polaris as po\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "competition = po.load_competition(\"asap-discovery/antiviral-potency-2025\")\n",
    "# or\n",
    "# competition = po.load_competition(\"asap-discovery/antiviral-admet-2025\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing Molecular Embeddings\n",
    "We can pick a number of different methods for representing molecules as a vector.\n",
    "For this notebook we will consider just two: `mordred` and ChemProp.\n",
    "The former uses a vector of ~1,600 molecular descriptors which can be calculated from the graph.\n",
    "This embedding is _fixed_ or _static_, i.e. it does not change during training.\n",
    "This has the advantage of packing a lot of chemical knowledge into the representation, but anything that we miss can't be added during training.\n",
    "ChemProp on the other hand is a _learned_ embedding, which will adapt during training to best regress our target.\n",
    "\n",
    "There is also the combination of the two - learn a representation during training, and then simply concatenate the molecular descriptors to said representation.\n",
    "This turned out to work better than either representation on its own for a few of the benchmarks (see the configuration dictionary below), but required some hyperparameter optimization (see `hopt.py`) to get decent results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING = {\n",
    "    'HLM': \"chemprop\",\n",
    "    'MLM': \"combined\",\n",
    "    'KSOL': \"mordred\",\n",
    "    'LogD': \"mordred\",\n",
    "    'MDR1-MDCKII': \"mordred\",\n",
    "    'pIC50 (MERS-CoV Mpro)': \"combined\",\n",
    "    'pIC50 (SARS-CoV-2 Mpro)': \"combined\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = competition.get_train_test_split()\n",
    "test_df: pd.DataFrame = test.as_dataframe()\n",
    "train_df: pd.DataFrame = train.as_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CXSMILES</th>\n",
       "      <th>pIC50 (MERS-CoV Mpro)</th>\n",
       "      <th>pIC50 (SARS-CoV-2 Mpro)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COC[C@]1(C)C(=O)N(C2=CN=CC3=CC=CC=C23)C(=O)N1C...</td>\n",
       "      <td>4.19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C=C(CN1CCC2=C(C=C(Cl)C=C2)C1C(=O)NC1=CN=CC2=CC...</td>\n",
       "      <td>4.92</td>\n",
       "      <td>5.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNC(=O)CN1C[C@]2(C[C@H](C)N(C3=CN=CC=C3C3CC3)C...</td>\n",
       "      <td>4.73</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C=C(CN1CCC2=C(C=C(Cl)C=C2)C1C(=O)NC1=CN=CC2=CC...</td>\n",
       "      <td>4.90</td>\n",
       "      <td>6.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C=C(CN1CCC2=C(C=C(Cl)C=C2)C1C(=O)NC1=CN=CC2=CC...</td>\n",
       "      <td>4.81</td>\n",
       "      <td>5.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>CNS(=O)(=O)OCC(=O)N1CCN(CC2=CC=CC(Cl)=C2)[C@H]...</td>\n",
       "      <td>5.57</td>\n",
       "      <td>6.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>O=C(CC1=CN=CC2=CC=CC=C12)N1CC[C@@H]2CCCC[C@H]2...</td>\n",
       "      <td>4.60</td>\n",
       "      <td>6.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>CNC(=O)[C@H]1CCCN(C(=O)CC2=CN=CC3=CC=CC=C23)C1...</td>\n",
       "      <td>4.22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>C[C@H]1CCCN(C(=O)CC2=CN=CC3=CC=CC=C23)[C@H]1C ...</td>\n",
       "      <td>4.40</td>\n",
       "      <td>5.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>O=C(O)C[C@H]1CCCN(C(=O)CC2=CN=CC3=CC=CC=C23)C1...</td>\n",
       "      <td>4.22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1031 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               CXSMILES  \\\n",
       "0     COC[C@]1(C)C(=O)N(C2=CN=CC3=CC=CC=C23)C(=O)N1C...   \n",
       "1     C=C(CN1CCC2=C(C=C(Cl)C=C2)C1C(=O)NC1=CN=CC2=CC...   \n",
       "2     CNC(=O)CN1C[C@]2(C[C@H](C)N(C3=CN=CC=C3C3CC3)C...   \n",
       "3     C=C(CN1CCC2=C(C=C(Cl)C=C2)C1C(=O)NC1=CN=CC2=CC...   \n",
       "4     C=C(CN1CCC2=C(C=C(Cl)C=C2)C1C(=O)NC1=CN=CC2=CC...   \n",
       "...                                                 ...   \n",
       "1026  CNS(=O)(=O)OCC(=O)N1CCN(CC2=CC=CC(Cl)=C2)[C@H]...   \n",
       "1027  O=C(CC1=CN=CC2=CC=CC=C12)N1CC[C@@H]2CCCC[C@H]2...   \n",
       "1028  CNC(=O)[C@H]1CCCN(C(=O)CC2=CN=CC3=CC=CC=C23)C1...   \n",
       "1029  C[C@H]1CCCN(C(=O)CC2=CN=CC3=CC=CC=C23)[C@H]1C ...   \n",
       "1030  O=C(O)C[C@H]1CCCN(C(=O)CC2=CN=CC3=CC=CC=C23)C1...   \n",
       "\n",
       "      pIC50 (MERS-CoV Mpro)  pIC50 (SARS-CoV-2 Mpro)  \n",
       "0                      4.19                      NaN  \n",
       "1                      4.92                     5.29  \n",
       "2                      4.73                      NaN  \n",
       "3                      4.90                     6.11  \n",
       "4                      4.81                     5.62  \n",
       "...                     ...                      ...  \n",
       "1026                   5.57                     6.38  \n",
       "1027                   4.60                     6.09  \n",
       "1028                   4.22                      NaN  \n",
       "1029                   4.40                     5.06  \n",
       "1030                   4.22                      NaN  \n",
       "\n",
       "[1031 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Per-Task Models\n",
    "`nepare` works by taking the difference in a target value for each input.\n",
    "Unfortunately this means that when target values are _missing_, we can't simply mask single inputs - we need to mask entire pairs.\n",
    "Rather than do this and end up with a really sparse training set, we will just train one model for each target property.\n",
    "\n",
    "This is OK in terms of the amount of training data we have - we might drop 25% of the data, but we end up squaring the amount of remaining data, nullifying the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import lightning\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks.model_checkpoint import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from chemprop.nn.agg import MeanAggregation\n",
    "from chemprop.nn.message_passing import BondMessagePassing\n",
    "from fastprop.data import standard_scale, inverse_standard_scale\n",
    "\n",
    "from nepare.data import PairwiseAugmentedDataset, PairwiseAnchoredDataset, PairwiseInferenceDataset\n",
    "from nepare.nn import LearnedEmbeddingNeuralPairwiseRegressor, NeuralPairwiseRegressor\n",
    "from nepare.inference import predict\n",
    "\n",
    "from utils.splitting import split\n",
    "from utils.chemprop_wrappers import smiles2molgraphcache, collate_fn, ChemPropEmbedder\n",
    "from utils.mordred_wrappers import smi2features\n",
    "from utils.metrics import evaluate_predictions\n",
    "from utils.combined_embeddings import MordredChemPropEmbedder, collate_fn_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This huge block of code is responsible for training each model, reporting its performance, and running inference on the test data.\n",
    "Check the inline comments for more explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jackson/neural-pairwise-regression/.venv/lib/python3.12/site-packages/mordred/_base/pandas_module.py:17: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  t[t.applymap(is_missing)] = value\n",
      "/home/jackson/neural-pairwise-regression/.venv/lib/python3.12/site-packages/mordred/_base/pandas_module.py:17: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  t[t.applymap(is_missing)] = value\n",
      "/home/jackson/neural-pairwise-regression/.venv/lib/python3.12/site-packages/mordred/_base/pandas_module.py:17: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  t[t.applymap(is_missing)] = value\n",
      "/home/jackson/neural-pairwise-regression/.venv/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'embedding_module' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['embedding_module'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/jackson/neural-pairwise-regression/.venv/lib/python3.12/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /home/jackson/neural-pairwise-regression/notebooks/polaris_asap/lightning_logs/combined_pIC50 (MERS-CoV Mpro) exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type                    | Params | Mode \n",
      "---------------------------------------------------------------------\n",
      "0 | fnn              | Sequential              | 6.2 M  | train\n",
      "1 | embedding_module | MordredChemPropEmbedder | 2.2 M  | train\n",
      "---------------------------------------------------------------------\n",
      "8.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "8.4 M     Total params\n",
      "33.560    Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f3b6cfd5e924ce9a3aa887aedb3fc92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d1a565310c34dd2bdd39e8adaf91426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fce9f9cba87427e8c7964e016cbdbd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc575fdbcb8a4d8188221ca47f6bbe5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "712029d64f8245449c822f81930487a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c928e1f84d7d4890b2d6814833723da7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c5f917447764ddc95833a43c2dfd12d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e608c6ec184761a4540f67151c6ff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1097cee65d74415801310cb262c8d29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2c61385821945b8a23a917303fd03bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2cc0385a3454ff69acbe2133da77278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "213bdebedd884da0ad7d1989d1a352c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3258e336f7a44a12b94394b07585dfa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d5f16ca08db4a8a879b5238fd7d69bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "280ff709a7eb4b9fa854cd9c60bae657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39c7d413e63a42dc80f2f9c55c465a7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c18051710fb4ef3a3a7104d4d51634f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_name='pIC50 (MERS-CoV Mpro)':\n",
      " - Pearson r: 0.4416\n",
      " - MSE: 0.6493\n",
      " - MAE: 0.5011\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b017dcae81884f048173e6eceec3afac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jackson/neural-pairwise-regression/.venv/lib/python3.12/site-packages/mordred/_base/pandas_module.py:17: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  t[t.applymap(is_missing)] = value\n",
      "/home/jackson/neural-pairwise-regression/.venv/lib/python3.12/site-packages/mordred/_base/pandas_module.py:17: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  t[t.applymap(is_missing)] = value\n",
      "/home/jackson/neural-pairwise-regression/.venv/lib/python3.12/site-packages/mordred/_base/pandas_module.py:17: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  t[t.applymap(is_missing)] = value\n",
      "/home/jackson/neural-pairwise-regression/.venv/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'embedding_module' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['embedding_module'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/jackson/neural-pairwise-regression/.venv/lib/python3.12/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /home/jackson/neural-pairwise-regression/notebooks/polaris_asap/lightning_logs/combined_pIC50 (SARS-CoV-2 Mpro) exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type                    | Params | Mode \n",
      "---------------------------------------------------------------------\n",
      "0 | fnn              | Sequential              | 6.2 M  | train\n",
      "1 | embedding_module | MordredChemPropEmbedder | 2.2 M  | train\n",
      "---------------------------------------------------------------------\n",
      "8.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "8.4 M     Total params\n",
      "33.560    Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "453eefe6258f43e7acdc73e5727b8173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c90b8965b1524de4a85036205b658d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c86cec0932b4ac19d8bad1bef67b05a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c55ec5aa9c34fc5b3b9636513ef85c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95d1c5c75c454692a30bc325265a4777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8080cac33ec046a89f2b95f60090390c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9751f4250ab04625ba4b14084bdd9801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83260aa77a6f46daa084473c1c6d5923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca6ee2a72002409da9dbe62469da6f7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bee30497057e4fc28488b2e1050b9abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dfcc283fa6a458692e76dc6f1de48cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba89b022ea9e41df9bdaa83b5a689d38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d87e827c9a79459ba81c104017aab6b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6262ca8fc06d47faa463899fd0c861da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f273b97b3def46188fe5847bc1c890bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7d1e0f7c1374ae39a37010b28c88834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "325a7aca1da34367b86ec6371f6d4ce6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c6ec7dede745f8a3fdd31427866601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99af36460a654ffe945cb087b98af8a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86196491e1774dc88875e230acdfed76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d64556d1513472c9914ab372e58548b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b3d1d0a734d4b4498d377691f9365f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbcaec24567e4db5b870d2f062e5fcba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23537b79ef2d4a5d9d2390d07829a383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1ea7473d08b47a0ba85d775f11c8c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_name='pIC50 (SARS-CoV-2 Mpro)':\n",
      " - Pearson r: 0.7630\n",
      " - MSE: 0.4684\n",
      " - MAE: 0.4600\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e8b89e57af040f595c4522bbcd03d7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = {}  # for polaris\n",
    "val_score = []  # for my own checking of model performance\n",
    "output_dir = Path(\"lightning_logs\")\n",
    "tasks = list(competition.target_cols)\n",
    "for task_n, task_name in enumerate(tasks):\n",
    "    # copy from the train dataframe each time to avoid accidentally messing up all the training data\n",
    "    task_df = train_df[[\"CXSMILES\", task_name]].copy()\n",
    "    task_df.dropna(inplace=True)\n",
    "    task_df.reset_index(inplace=True)\n",
    "\n",
    "    # this function splits the data into a training set (for setting weights) and validation set (for early stopping)\n",
    "    # the validation set will be equal in size to the test dataframe and composed of 50% randomly selected molecules\n",
    "    # and the remainder molecular that are highly similar to the test molecules \n",
    "    train_idxs, val_idxs = split(task_df[\"CXSMILES\"], test_df[\"CXSMILES\"])\n",
    "\n",
    "    # rescale our target values, both for metric reporting and NN performance\n",
    "    train_targets = torch.tensor(task_df[task_name].iloc[train_idxs].to_numpy(), dtype=torch.float32).reshape(-1, 1)  # 2d!\n",
    "    train_targets, target_means, target_vars = standard_scale(train_targets)\n",
    "    val_targets = torch.tensor(task_df[task_name].iloc[val_idxs].to_numpy(), dtype=torch.float32).reshape(-1, 1)  # 2d!\n",
    "    val_targets = standard_scale(val_targets, target_means, target_vars)\n",
    "\n",
    "    # avoid some code duplication\n",
    "    dataset_kwargs = dict(batch_size=64)\n",
    "\n",
    "    # each embedding does fundamentally the same thing:\n",
    "    # - turn the molecules into tensors\n",
    "    # - pack those tensors into a nepare dataset that auto-magically augments it\n",
    "    # - initializes the model\n",
    "    #\n",
    "    # the big difference is that embeddings using ChemProp have a special function for collating\n",
    "    # their batches and also must instantiate an additional module used to learn an embedding\n",
    "    if EMBEDDING[task_name] == \"mordred\":\n",
    "        Model = NeuralPairwiseRegressor\n",
    "        train_features, feature_means, feature_vars = smi2features(task_df[\"CXSMILES\"][train_idxs])\n",
    "        val_features, _, _ = smi2features(task_df[\"CXSMILES\"][val_idxs], feature_means, feature_vars)\n",
    "        test_features, _, _ = smi2features(test_df[\"CXSMILES\"], feature_means, feature_vars)\n",
    "        # setup the datasets\n",
    "        train_dataset = PairwiseAugmentedDataset(train_features, train_targets, how='full')\n",
    "        val_dataset = PairwiseAnchoredDataset(train_features, train_targets, val_features, val_targets, how='full')\n",
    "        val_absolute_dataset = PairwiseInferenceDataset(train_features, train_targets, val_features, how='full')\n",
    "        test_dataset = PairwiseInferenceDataset(train_features, train_targets, test_features, how='full')\n",
    "        # build the model\n",
    "        npr = Model(train_features.shape[1], 70, 3)\n",
    "    elif EMBEDDING[task_name] == \"chemprop\":\n",
    "        Model = LearnedEmbeddingNeuralPairwiseRegressor\n",
    "        # featurize the data\n",
    "        train_mgc = smiles2molgraphcache(task_df[\"CXSMILES\"][train_idxs])\n",
    "        val_mgc = smiles2molgraphcache(task_df[\"CXSMILES\"][val_idxs])\n",
    "        test_mgc = smiles2molgraphcache(test_df[\"CXSMILES\"])\n",
    "        # setup the datasets\n",
    "        dataset_kwargs[\"collate_fn\"] = collate_fn\n",
    "        train_dataset = PairwiseAugmentedDataset(train_mgc, train_targets, how='sut')\n",
    "        val_dataset = PairwiseAnchoredDataset(train_mgc, train_targets, val_mgc, val_targets, how='half')\n",
    "        val_absolute_dataset = PairwiseInferenceDataset(train_mgc, train_targets, val_mgc, how='half')\n",
    "        test_dataset = PairwiseInferenceDataset(train_mgc, train_targets, test_mgc, how='half')\n",
    "        # build the model\n",
    "        mp = BondMessagePassing(d_h=400)\n",
    "        agg = MeanAggregation()\n",
    "        embedder = ChemPropEmbedder(mp, agg)\n",
    "        npr = Model(embedder, 400, 200, 2, lr=5e-5)\n",
    "    elif EMBEDDING[task_name] == \"combined\":\n",
    "        Model = LearnedEmbeddingNeuralPairwiseRegressor\n",
    "        # featurize the data\n",
    "        train_features, feature_means, feature_vars = smi2features(task_df[\"CXSMILES\"][train_idxs])\n",
    "        val_features, _, _ = smi2features(task_df[\"CXSMILES\"][val_idxs], feature_means, feature_vars)\n",
    "        test_features, _, _ = smi2features(test_df[\"CXSMILES\"], feature_means, feature_vars)\n",
    "        train_mgc = smiles2molgraphcache(task_df[\"CXSMILES\"][train_idxs])\n",
    "        val_mgc = smiles2molgraphcache(task_df[\"CXSMILES\"][val_idxs])\n",
    "        test_mgc = smiles2molgraphcache(test_df[\"CXSMILES\"])\n",
    "        train_tuples = [(train_mgc[i], train_features[i, :]) for i in range(len(train_targets))]\n",
    "        val_tuples = [(val_mgc[i], val_features[i, :]) for i in range(len(val_targets))]\n",
    "        test_tuples = [(test_mgc[i], test_features[i, :]) for i in range(len(test_mgc))]\n",
    "        # setup the datasets\n",
    "        train_dataset = PairwiseAugmentedDataset(train_tuples, train_targets, how='full')\n",
    "        val_dataset = PairwiseAnchoredDataset(train_tuples, train_targets, val_tuples, val_targets, how='full')\n",
    "        val_absolute_dataset = PairwiseInferenceDataset(train_tuples, train_targets, val_tuples, how='full')\n",
    "        test_dataset = PairwiseInferenceDataset(train_tuples, train_targets, test_tuples, how='full')\n",
    "        dataset_kwargs[\"collate_fn\"] = collate_fn_combined\n",
    "        # build the model\n",
    "        mp = BondMessagePassing(d_h=1_000, depth=2)\n",
    "        agg = MeanAggregation()\n",
    "        embedder = MordredChemPropEmbedder(mp, agg)\n",
    "        npr = Model(embedder, mp.output_dim + train_features.shape[1], 1_000, 2, lr=5e-5)\n",
    "\n",
    "\n",
    "    # classic lightning training, inference\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, **dataset_kwargs)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, **dataset_kwargs)\n",
    "    val_absolute_loader = torch.utils.data.DataLoader(val_absolute_dataset, **dataset_kwargs)\n",
    "    predict_loader = torch.utils.data.DataLoader(test_dataset, **dataset_kwargs)\n",
    "    early_stopping = EarlyStopping(monitor=\"validation/loss\", patience=3)\n",
    "    name = \"_\".join([EMBEDDING[task_name], task_name])\n",
    "    model_checkpoint = ModelCheckpoint(dirpath=output_dir / name, monitor=\"validation/loss\")\n",
    "    logger = TensorBoardLogger(save_dir=output_dir, name=name, default_hp_metric=False)\n",
    "    trainer = lightning.Trainer(max_epochs=50, log_every_n_steps=1, callbacks=[early_stopping, model_checkpoint], logger=logger)\n",
    "    trainer.fit(npr, train_loader, val_loader)\n",
    "    npr = Model.load_from_checkpoint(model_checkpoint.best_model_path)\n",
    "\n",
    "    # we use the predict function from nepare, which automatically maps difference-space predictions back to absolute space\n",
    "    y_pred, y_stdev = predict(npr, val_absolute_loader)\n",
    "\n",
    "    # checking our performance on the validation set\n",
    "    # leave in the scaled space so that the average is weighted equally among the targets\n",
    "    results_dict = evaluate_predictions(val_targets.flatten().numpy(), y_pred.flatten().numpy())\n",
    "    val_score.append((len(val_targets), results_dict[\"MAE\"]))\n",
    "    # now go back to correct scale\n",
    "    y_pred = inverse_standard_scale(y_pred, target_means, target_vars)\n",
    "    y_true = inverse_standard_scale(val_targets, target_means, target_vars)\n",
    "    print(f\"{task_name=}:\\n - {\"\\n - \".join([f'{name}: {score:.4f}' for name, score in evaluate_predictions(y_true.flatten().numpy(), y_pred.flatten().numpy()).items()])}\")\n",
    "\n",
    "    # finally predict on the test set, descale, and save them for later\n",
    "    y_pred, y_stdev = predict(npr, predict_loader)\n",
    "    y_pred = inverse_standard_scale(y_pred, target_means, target_vars)\n",
    "    predictions[task_name] = y_pred.flatten().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hope is that the below number roughly matches with the actual performance on the `polaris` leaderboard.\n",
    "I say _hope_ because the composition of the blind test set and my validation set will invariably be different, just hopefully not _so_ different that the validation set actually causes _bad_ early stopping (i.e. too early or too late)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Scaled Weighted Average MAE 0.5112\n"
     ]
    }
   ],
   "source": [
    "print(f\"Validation Scaled Weighted Average MAE {sum(n*s for n, s in val_score) / sum(n for n, _ in val_score):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This last block is commented out because it will fail (unless you are me) - you can replace the inputs with your own if you are submitting this for yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d98181a02cb4f35a5c18803b68cdc25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12:38:11] </span><span style=\"color: #008000; text-decoration-color: #008000\"> Success: Submitting competition predictions</span>                                               <a href=\"file:///home/jackson/neural-pairwise-regression/.venv/lib/python3.12/site-packages/polaris/utils/context.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">context.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/jackson/neural-pairwise-regression/.venv/lib/python3.12/site-packages/polaris/utils/context.py#53\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">53</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12:38:11]\u001b[0m\u001b[2;36m \u001b[0m\u001b[32m Success: Submitting competition predictions\u001b[0m                                               \u001b]8;id=271518;file:///home/jackson/neural-pairwise-regression/.venv/lib/python3.12/site-packages/polaris/utils/context.py\u001b\\\u001b[2mcontext.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=68544;file:///home/jackson/neural-pairwise-regression/.venv/lib/python3.12/site-packages/polaris/utils/context.py#53\u001b\\\u001b[2m53\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "competition.submit_predictions(\n",
    "    predictions=predictions,\n",
    "    prediction_name=\"nepare\",\n",
    "    prediction_owner=\"jacksonburns\",\n",
    "    report_url=\"https://github.com/JacksonBurns/neural-pairwise-regression/blob/main/meta\",\n",
    "    github_url = \"https://github.com/JacksonBurns/neural-pairwise-regression/blob/main/notebooks/polaris_asap/main.ipynb\",\n",
    "    description = \"Neural Pairwise Regression with ChemProp as a learnable embedding\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
