{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `nepare` ASAP `polaris` Competition\n",
    "\n",
    "This notebook demonstrates using Neural Pairwise Regression (via `nepare`) with the `polaris` benchmarking library to compete in the ASAP discovery competition.\n",
    "\n",
    "See the `meta` directory in the `nepare` repository for some more theoretical exploration of what this notebook does.\n",
    "\n",
    "## Requirements\n",
    "This should work on Python 3.10 or newer - I ran with 3.12\n",
    "\n",
    "The following dependencies are required:\n",
    " - polaris-lib >=0.11.6\n",
    " - pandas\n",
    " - rdkit\n",
    " - lightning\n",
    " - torch\n",
    " - fastprop\n",
    " - mordredcommunity\n",
    " - chemprop ~2.1\n",
    " - ipywidgets\n",
    "\n",
    "You will also need to run `pip install .` in the repository's root directory to install `nepare`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `polaris` Setup\n",
    "\n",
    "After running `polaris login` on the command line, we can import everything (checking that the version is recent enough) and then download the benchmark data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polaris as po\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "competition = po.load_competition(\"asap-discovery/antiviral-potency-2025\")\n",
    "# or\n",
    "# competition = po.load_competition(\"asap-discovery/antiviral-admet-2025\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = competition.get_train_test_split()\n",
    "test_df: pd.DataFrame = test.as_dataframe()\n",
    "train_df: pd.DataFrame = train.as_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CXSMILES</th>\n",
       "      <th>pIC50 (SARS-CoV-2 Mpro)</th>\n",
       "      <th>pIC50 (MERS-CoV Mpro)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COC[C@]1(C)C(=O)N(C2=CN=CC3=CC=CC=C23)C(=O)N1C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C=C(CN1CCC2=C(C=C(Cl)C=C2)C1C(=O)NC1=CN=CC2=CC...</td>\n",
       "      <td>5.29</td>\n",
       "      <td>4.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNC(=O)CN1C[C@]2(C[C@H](C)N(C3=CN=CC=C3C3CC3)C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C=C(CN1CCC2=C(C=C(Cl)C=C2)C1C(=O)NC1=CN=CC2=CC...</td>\n",
       "      <td>6.11</td>\n",
       "      <td>4.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C=C(CN1CCC2=C(C=C(Cl)C=C2)C1C(=O)NC1=CN=CC2=CC...</td>\n",
       "      <td>5.62</td>\n",
       "      <td>4.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>CNS(=O)(=O)OCC(=O)N1CCN(CC2=CC=CC(Cl)=C2)[C@H]...</td>\n",
       "      <td>6.38</td>\n",
       "      <td>5.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>O=C(CC1=CN=CC2=CC=CC=C12)N1CC[C@@H]2CCCC[C@H]2...</td>\n",
       "      <td>6.09</td>\n",
       "      <td>4.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>CNC(=O)[C@H]1CCCN(C(=O)CC2=CN=CC3=CC=CC=C23)C1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>C[C@H]1CCCN(C(=O)CC2=CN=CC3=CC=CC=C23)[C@H]1C ...</td>\n",
       "      <td>5.06</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>O=C(O)C[C@H]1CCCN(C(=O)CC2=CN=CC3=CC=CC=C23)C1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1031 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               CXSMILES  \\\n",
       "0     COC[C@]1(C)C(=O)N(C2=CN=CC3=CC=CC=C23)C(=O)N1C...   \n",
       "1     C=C(CN1CCC2=C(C=C(Cl)C=C2)C1C(=O)NC1=CN=CC2=CC...   \n",
       "2     CNC(=O)CN1C[C@]2(C[C@H](C)N(C3=CN=CC=C3C3CC3)C...   \n",
       "3     C=C(CN1CCC2=C(C=C(Cl)C=C2)C1C(=O)NC1=CN=CC2=CC...   \n",
       "4     C=C(CN1CCC2=C(C=C(Cl)C=C2)C1C(=O)NC1=CN=CC2=CC...   \n",
       "...                                                 ...   \n",
       "1026  CNS(=O)(=O)OCC(=O)N1CCN(CC2=CC=CC(Cl)=C2)[C@H]...   \n",
       "1027  O=C(CC1=CN=CC2=CC=CC=C12)N1CC[C@@H]2CCCC[C@H]2...   \n",
       "1028  CNC(=O)[C@H]1CCCN(C(=O)CC2=CN=CC3=CC=CC=C23)C1...   \n",
       "1029  C[C@H]1CCCN(C(=O)CC2=CN=CC3=CC=CC=C23)[C@H]1C ...   \n",
       "1030  O=C(O)C[C@H]1CCCN(C(=O)CC2=CN=CC3=CC=CC=C23)C1...   \n",
       "\n",
       "      pIC50 (SARS-CoV-2 Mpro)  pIC50 (MERS-CoV Mpro)  \n",
       "0                         NaN                   4.19  \n",
       "1                        5.29                   4.92  \n",
       "2                         NaN                   4.73  \n",
       "3                        6.11                   4.90  \n",
       "4                        5.62                   4.81  \n",
       "...                       ...                    ...  \n",
       "1026                     6.38                   5.57  \n",
       "1027                     6.09                   4.60  \n",
       "1028                      NaN                   4.22  \n",
       "1029                     5.06                   4.40  \n",
       "1030                      NaN                   4.22  \n",
       "\n",
       "[1031 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup\n",
    "We can pick a number of different methods for representing molecules as a vector.\n",
    "For this notebook we will consider just two: `mordred` and ChemProp.\n",
    "The former uses a vector of ~1,600 molecular descriptors which can be calculated from the graph.\n",
    "This embedding is _fixed_ or _static_, i.e. it does not change during training.\n",
    "This has the advantage of packing a lot of chemical knowledge into the representation, but anything that we miss can't be added during training.\n",
    "ChemProp on the other hand is a _learned_ embedding, which will adapt during training to best regress our target.\n",
    "\n",
    "There is also the combination of the two - learn a representation during training, and then simply concatenate the molecular descriptors to said representation.\n",
    "In _theory_ this should cover the advantages of the two approaches, so we'll use it here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define an Embedding Module for `nepare`\n",
    "We can pass a custom-built module for learning an embedding during training as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import OrderedDict\n",
    "\n",
    "import torch\n",
    "\n",
    "class MordredChempropEmbedder(torch.nn.Module):\n",
    "    def __init__(self, mp, agg, mordred_size, mordred_layers):\n",
    "        super().__init__()\n",
    "        # chemprop\n",
    "        self.mp = mp\n",
    "        self.agg = agg\n",
    "\n",
    "        # mordred\n",
    "        _modules = OrderedDict()\n",
    "        _modules[\"feature_dropout\"] = torch.nn.Dropout(0.80)\n",
    "        activation = torch.nn.ReLU\n",
    "        for i in range(mordred_layers):\n",
    "            _modules[f\"hidden_{i}\"] = torch.nn.Linear(1_613 if i == 0 else mordred_size, mordred_size)\n",
    "            if i < (mordred_layers - 1):  # skip on last\n",
    "                _modules[f\"{activation.__name__.lower()}_{i}\"] = activation()\n",
    "                _modules[f\"dropout_{i}\"] = torch.nn.Dropout(0.5)\n",
    "        self.fnn = torch.nn.Sequential(_modules)\n",
    "\n",
    "        # shared\n",
    "        self.bn = torch.nn.BatchNorm1d(mp.output_dim + mordred_size)\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "        self.relu = activation()\n",
    "\n",
    "    def forward(self, batch):\n",
    "        bmg, feats = batch\n",
    "        H = self.mp(bmg)\n",
    "        Z = self.agg(H, bmg.batch)\n",
    "        f = self.fnn(feats)\n",
    "        return self.relu(self.dropout(self.bn(torch.cat((Z, f), dim=1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A note on the architecture - we aggressively regularize the `mordred` features to prevent the model using only those instead of ChemProp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying Validation Set\n",
    "My experience so far shows that these pairwise difference learning networks tend to overfit _very_ easily (thus all the regularization).\n",
    "We need to use early stopping to deal with this, and since we know what area of chemical space we want to extrapolate into we can also choose our validation set to reflect this. We will also downsample the data (again, overfitting) during this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import Random\n",
    "\n",
    "from rdkit.Chem import DataStructs, rdFingerprintGenerator\n",
    "from rdkit import Chem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just a convenience function that looks like the old RDKit fingerprint generation syntax (I prefer the old way `¯\\_(ツ)_/¯`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _smi2fp(smi):\n",
    "    fpg = rdFingerprintGenerator.GetMorganGenerator(radius=4)\n",
    "    return fpg.GetFingerprint(Chem.MolFromSmiles(smi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want our validation set to tell us to stop training once we start failing to extrapolate to the new chemical space in the test set that we care about.\n",
    "At the same time, we want to train on that chemical so that we can improve model performance.\n",
    "\n",
    "To that end, we have this `split` function, which selects a training set of equal size to the test set such that the most similar molecule in the available data to each test point is present (or the _n_-th most similar, if the most has already been selected) in training.\n",
    "We then randomly select some of the un-selected points for validation to control early stopping.\n",
    "During validation all validation points are anchored against the training data, so this will give us a good idea of when the chemical space of the validation set has been well fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(train_smis, test_smis):\n",
    "    train_fps = list(map(_smi2fp, train_smis))\n",
    "    test_fps = list(map(_smi2fp, test_smis))\n",
    "\n",
    "    train_idxs = set()  # specifically use a set here to avoid duplicates\n",
    "    for fp in test_fps:\n",
    "        sims = [(i, DataStructs.FingerprintSimilarity(fp, _fp)) for i, _fp in enumerate(train_fps)]\n",
    "        while 1:  # continue selecting the most similar molecule until one is found which is not already selected\n",
    "            most_similar_idx = max(sims, key=lambda t: t[1])[0]\n",
    "            if most_similar_idx in train_idxs:\n",
    "                sims[most_similar_idx] = (most_similar_idx, 0.0)\n",
    "            else:\n",
    "                train_idxs.add(most_similar_idx)\n",
    "                break\n",
    "    train_idxs = list(train_idxs)\n",
    "\n",
    "    rng = Random(42)\n",
    "    rng.shuffle(train_idxs)\n",
    "    _n = int(len(train_idxs) * 0.05)\n",
    "    val_idxs = train_idxs[:_n]\n",
    "    train_idxs = train_idxs[_n:]\n",
    "\n",
    "    return train_idxs, val_idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers\n",
    "Finally, before we start training, we will define some functions and classes for dataloading, featurization, etc.\n",
    "\n",
    "Most of these aren't commented, but they generally only wrap other well-documented code or do something obvious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import MolFromSmiles\n",
    "from chemprop.featurizers import MolGraphCache, SimpleMoleculeMolGraphFeaturizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "map `list[SMILES] -> list[chemprop MolGraphs]`\n",
    "we use `MolGraphCache` here (so that one could easily substitute `MolGraphCacheOnTheFly`) but we would instead just ust `mgc = list(map(featurizer, mols))` in place of this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smiles2molgraphcache(smiles: list[str]):\n",
    "    mols = list(map(MolFromSmiles, smiles))\n",
    "    featurizer = SimpleMoleculeMolGraphFeaturizer()\n",
    "    mgc = MolGraphCache(mols, [None] * len(mols), [None] * len(mols), featurizer)\n",
    "    return mgc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mordred import Calculator, descriptors\n",
    "from fastprop.data import standard_scale\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "map `list[SMILES]` -> imputed, scaled, winsorized features tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smi2features(smis, feature_means=None, feature_vars=None):\n",
    "    calc = Calculator(descriptors, ignore_3D=True)\n",
    "    train_features = calc.pandas(map(MolFromSmiles, smis), nmols=len(smis), quiet=True).fill_missing()\n",
    "    X = torch.tensor(train_features.to_numpy(dtype=np.float32), dtype=torch.float32)\n",
    "    if feature_means is None or feature_vars is None:\n",
    "        X, feature_means, feature_vars = standard_scale(X)\n",
    "    else:\n",
    "        X = standard_scale(X, feature_means, feature_vars)\n",
    "    X.clamp_(-3, 3)\n",
    "    return X, feature_means, feature_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "\n",
    "from chemprop.data import MolGraph, BatchMolGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _collate_fn(batch: Iterable[tuple[tuple[MolGraph, torch.Tensor], tuple[MolGraph, torch.Tensor], float]]):\n",
    "    mgs_1, feats_1, mgs_2, feats_2, ys = [], [], [], [], []\n",
    "    for item in batch:\n",
    "        mgs_1.append(item[0][0])\n",
    "        feats_1.append(item[0][1])\n",
    "        mgs_2.append(item[1][0])\n",
    "        feats_2.append(item[1][1])\n",
    "        ys.append(item[2])\n",
    "    return ((BatchMolGraph(mgs_1), torch.stack(feats_1, dim=0)), (BatchMolGraph(mgs_2), torch.stack(feats_2, dim=0)), torch.tensor(np.array(ys), dtype=torch.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(y_true, y_pred):\n",
    "    return {\"Pearson r\": pearsonr(y_true, y_pred).correlation, \"MSE\": mean_squared_error(y_true, y_pred), \"MAE\": mean_absolute_error(y_true, y_pred)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Per-Task Models\n",
    "`nepare` works by taking the difference in a target value for each input.\n",
    "Unfortunately this means that when target values are _missing_, we can't simply mask single inputs - we need to mask entire pairs.\n",
    "Rather than do this and end up with a really sparse training set, we will just train one model for each target property.\n",
    "\n",
    "This is OK in terms of the amount of training data we have - we might drop 25% of the data, but we end up squaring the amount of remaining data, nullifying the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import lightning\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks.model_checkpoint import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from chemprop.nn.agg import MeanAggregation\n",
    "from chemprop.nn.message_passing import BondMessagePassing\n",
    "from fastprop.data import standard_scale, inverse_standard_scale\n",
    "\n",
    "from nepare.data import PairwiseAugmentedDataset, PairwiseAnchoredDataset, PairwiseInferenceDataset\n",
    "from nepare.nn import LearnedEmbeddingNeuralPairwiseRegressor\n",
    "from nepare.inference import predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This huge block of code is responsible for training each model, reporting its performance, and running inference on the test data.\n",
    "Check the inline comments for more explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jackson/neural-pairwise-regression/.venv/lib/python3.12/site-packages/mordred/_base/pandas_module.py:17: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  t[t.applymap(is_missing)] = value\n",
      "/home/jackson/neural-pairwise-regression/.venv/lib/python3.12/site-packages/mordred/_base/pandas_module.py:17: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  t[t.applymap(is_missing)] = value\n",
      "/home/jackson/neural-pairwise-regression/.venv/lib/python3.12/site-packages/mordred/_base/pandas_module.py:17: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  t[t.applymap(is_missing)] = value\n",
      "/home/jackson/neural-pairwise-regression/.venv/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'embedding_module' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['embedding_module'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/jackson/neural-pairwise-regression/.venv/lib/python3.12/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /home/jackson/neural-pairwise-regression/notebooks/lightning_logs/pIC50__SARS_CoV_2_Mpro_ exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type                    | Params | Mode \n",
      "---------------------------------------------------------------------\n",
      "0 | fnn              | Sequential              | 66.0 K | train\n",
      "1 | embedding_module | MordredChempropEmbedder | 130 K  | train\n",
      "---------------------------------------------------------------------\n",
      "196 K     Trainable params\n",
      "0         Non-trainable params\n",
      "196 K     Total params\n",
      "0.785     Total estimated model params size (MB)\n",
      "30        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LearnedEmbeddingNeuralPairwiseRegressor(\n",
      "  (fnn): Sequential(\n",
      "    (hidden_0): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (relu_0): ReLU()\n",
      "    (hidden_1): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (relu_1): ReLU()\n",
      "    (hidden_2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (relu_2): ReLU()\n",
      "    (readout): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      "  (embedding_module): MordredChempropEmbedder(\n",
      "    (mp): BondMessagePassing(\n",
      "      (W_i): Linear(in_features=86, out_features=64, bias=False)\n",
      "      (W_h): Linear(in_features=64, out_features=64, bias=False)\n",
      "      (W_o): Linear(in_features=136, out_features=64, bias=True)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (tau): ReLU()\n",
      "      (V_d_transform): Identity()\n",
      "      (graph_transform): Identity()\n",
      "    )\n",
      "    (agg): MeanAggregation()\n",
      "    (fnn): Sequential(\n",
      "      (feature_dropout): Dropout(p=0.8, inplace=False)\n",
      "      (hidden_0): Linear(in_features=1613, out_features=64, bias=True)\n",
      "      (relu_0): ReLU()\n",
      "      (dropout_0): Dropout(p=0.5, inplace=False)\n",
      "      (hidden_1): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (relu_1): ReLU()\n",
      "      (dropout_1): Dropout(p=0.5, inplace=False)\n",
      "      (hidden_2): Linear(in_features=64, out_features=64, bias=True)\n",
      "    )\n",
      "    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (relu): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5c2f6ae655e4a209f187a99743ce785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03f8d090249a4c8e9251d8bd0103545e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8532c17c65cc4b078866435e823cbfa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92ef1132a90741c0bb16f40348a23ca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81e7d75349124a8ba238c119bb50bd5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b61828d10ba46c1879c76ae786d44f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99d8ebb89cd544bb8462250ad8d3c078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "878fe98f5eb0418a9508d7055eeb734f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da869133ac7414ca7c56252323030d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7acd887aceed4892858bcb0d07d33d14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a456800236648cdaafb678ba24042ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9c560bc77254716af70113612ad24c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "450fbac3d169407faf0279ef79cdc7bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d3870f0094b4773bd7a7b5bf3d0f5fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9158c844bf74456b48b82f2fc8bdf60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38cd8e77d1d4480bbc49a50546d3c33d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b4032d30f1c403f92e908fcfca75317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1ef520e2f98465daf46ec5442e68ed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e30e61e55a28488d89b0a7239639311d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fb86e8deb24430f97fda41bdccf6838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2ee71d99e954f648f8b2f724e6fe4be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9af98da235c4eacabbe35c723225c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2525a28de8db4d6faa0af3316393a8fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26b2069629264c56bde91bc1bf641e7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e692c26868a0492a94d41fa6be191640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "215dbd7898cf44d1b2d96a66959952ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9da7abc2eb084552921160ea1beff99b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_name='pIC50 (SARS-CoV-2 Mpro)':\n",
      " - Pearson r: 0.9395\n",
      " - MSE: 0.1313\n",
      " - MAE: 0.2813\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95cd13faea2348aba781b8a4fb5576ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jackson/neural-pairwise-regression/.venv/lib/python3.12/site-packages/mordred/_base/pandas_module.py:17: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  t[t.applymap(is_missing)] = value\n",
      "/home/jackson/neural-pairwise-regression/.venv/lib/python3.12/site-packages/mordred/_base/pandas_module.py:17: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  t[t.applymap(is_missing)] = value\n",
      "/home/jackson/neural-pairwise-regression/.venv/lib/python3.12/site-packages/mordred/_base/pandas_module.py:17: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  t[t.applymap(is_missing)] = value\n",
      "/home/jackson/neural-pairwise-regression/.venv/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'embedding_module' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['embedding_module'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/jackson/neural-pairwise-regression/.venv/lib/python3.12/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /home/jackson/neural-pairwise-regression/notebooks/lightning_logs/pIC50__MERS_CoV_Mpro_ exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type                    | Params | Mode \n",
      "---------------------------------------------------------------------\n",
      "0 | fnn              | Sequential              | 66.0 K | train\n",
      "1 | embedding_module | MordredChempropEmbedder | 130 K  | train\n",
      "---------------------------------------------------------------------\n",
      "196 K     Trainable params\n",
      "0         Non-trainable params\n",
      "196 K     Total params\n",
      "0.785     Total estimated model params size (MB)\n",
      "30        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LearnedEmbeddingNeuralPairwiseRegressor(\n",
      "  (fnn): Sequential(\n",
      "    (hidden_0): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (relu_0): ReLU()\n",
      "    (hidden_1): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (relu_1): ReLU()\n",
      "    (hidden_2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (relu_2): ReLU()\n",
      "    (readout): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      "  (embedding_module): MordredChempropEmbedder(\n",
      "    (mp): BondMessagePassing(\n",
      "      (W_i): Linear(in_features=86, out_features=64, bias=False)\n",
      "      (W_h): Linear(in_features=64, out_features=64, bias=False)\n",
      "      (W_o): Linear(in_features=136, out_features=64, bias=True)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (tau): ReLU()\n",
      "      (V_d_transform): Identity()\n",
      "      (graph_transform): Identity()\n",
      "    )\n",
      "    (agg): MeanAggregation()\n",
      "    (fnn): Sequential(\n",
      "      (feature_dropout): Dropout(p=0.8, inplace=False)\n",
      "      (hidden_0): Linear(in_features=1613, out_features=64, bias=True)\n",
      "      (relu_0): ReLU()\n",
      "      (dropout_0): Dropout(p=0.5, inplace=False)\n",
      "      (hidden_1): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (relu_1): ReLU()\n",
      "      (dropout_1): Dropout(p=0.5, inplace=False)\n",
      "      (hidden_2): Linear(in_features=64, out_features=64, bias=True)\n",
      "    )\n",
      "    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (relu): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cf3d138b98a4c18a984d7ff2092a4a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9996c98e04d84baea6eb779fdfa1be0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba2097fa8e94b8d9b2a86eada41ba91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6d9038c146c407796fd8acaffdeb129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da80a16fd1d94971be26f47fead065f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4d125d6ed344be4a78a307ee51388f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "363ae6c2d5034f58a82c8e7626520d17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a5b10b8986b4b3aa97830db8d7a0901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b954bf412efc444f9cc7ab55e6fb4e7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e2a7dd0d5e34ff8a6aeda9198c93ea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47c29a2b3ef6486e8edad3dd8bf43618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc4bcdfa00b542f5b798bfa59c671264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76c099f2807f4b07bcff4105b840f1a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e28d0d0c19a5421c82e886fd31adc986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66f241bf81774ef9af889ffc9b0c0ca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c192a2af4147cc83667deb83750c45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "675c93f5376946ec8a8d483107714c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dacf908d8df94a5aa71c3d04192fb69e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a6085cd7ac1426eb7d143bb03735d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f776729c64514d89b5f384dedaff7265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c4b0015c3ef472193004d442a5a4a23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c559c47a6c124a89bcd01c761c6c9923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f789e1dc27f943fbb0817e64db03fa43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f4fd593272e411caeab6320a3285613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b50331525c3a46719ba2f615c52cd081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "514080acb51c4ea79faf11edf0a7d47d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37c784b4d2f84cc0806e3e75d0da1c3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86168b2dcf3c4355b5c84fdd2da04907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fda6f6042cd4d24896bd795da9782d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5687621dba184581b918f2e1c29ca759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05d416b510194323b46697dd6b1f3746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91166b33e0ae471c8ac102274c8d7e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f61b398df9e242d9adefb77f2ab94e2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_name='pIC50 (MERS-CoV Mpro)':\n",
      " - Pearson r: 0.7336\n",
      " - MSE: 0.3083\n",
      " - MAE: 0.4298\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9d34d7c87ac4b5fa6513e64bbc6e26a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = {}  # for polaris\n",
    "val_score = []  # for my own checking of model performance\n",
    "output_dir = Path(\"lightning_logs\")\n",
    "tasks = list(competition.target_cols)\n",
    "for task_n, task_name in enumerate(tasks):\n",
    "    # copy from the train dataframe each time to avoid accidentally messing up all the training data\n",
    "    task_df = train_df[[\"CXSMILES\", task_name]].copy()\n",
    "    task_df.dropna(inplace=True)\n",
    "    task_df.reset_index(inplace=True)\n",
    "\n",
    "    train_idxs, val_idxs = split(task_df[\"CXSMILES\"], test_df[\"CXSMILES\"])\n",
    "\n",
    "    # rescale our target values, both for metric reporting and NN performance\n",
    "    train_targets = torch.tensor(task_df[task_name].iloc[train_idxs].to_numpy(), dtype=torch.float32).reshape(-1, 1)  # 2d!\n",
    "    train_targets, target_means, target_vars = standard_scale(train_targets)\n",
    "    val_targets = torch.tensor(task_df[task_name].iloc[val_idxs].to_numpy(), dtype=torch.float32).reshape(-1, 1)  # 2d!\n",
    "    val_targets = standard_scale(val_targets, target_means, target_vars)\n",
    "\n",
    "    # featurize the data\n",
    "    train_features, feature_means, feature_vars = smi2features(task_df[\"CXSMILES\"][train_idxs])\n",
    "    val_features, _, _ = smi2features(task_df[\"CXSMILES\"][val_idxs], feature_means, feature_vars)\n",
    "    test_features, _, _ = smi2features(test_df[\"CXSMILES\"], feature_means, feature_vars)\n",
    "    train_mgc = smiles2molgraphcache(task_df[\"CXSMILES\"][train_idxs])\n",
    "    val_mgc = smiles2molgraphcache(task_df[\"CXSMILES\"][val_idxs])\n",
    "    test_mgc = smiles2molgraphcache(test_df[\"CXSMILES\"])\n",
    "    train_tuples = [(train_mgc[i], train_features[i, :]) for i in range(len(train_targets))]\n",
    "    val_tuples = [(val_mgc[i], val_features[i, :]) for i in range(len(val_targets))]\n",
    "    test_tuples = [(test_mgc[i], test_features[i, :]) for i in range(len(test_mgc))]\n",
    "    # setup the datasets\n",
    "    train_dataset = PairwiseAugmentedDataset(train_tuples, train_targets, how='sut')\n",
    "    val_dataset = PairwiseAnchoredDataset(train_tuples, train_targets, val_tuples, val_targets, how='half')\n",
    "    val_absolute_dataset = PairwiseInferenceDataset(train_tuples, train_targets, val_tuples, how='half')\n",
    "    test_dataset = PairwiseInferenceDataset(train_tuples, train_targets, test_tuples, how='half')\n",
    "    # build the model\n",
    "    _size = 64\n",
    "    _layers = 3\n",
    "    mp = BondMessagePassing(d_h=_size, depth=_layers)\n",
    "    agg = MeanAggregation()\n",
    "    embedder = MordredChempropEmbedder(mp, agg, _size, _layers)\n",
    "    npr = LearnedEmbeddingNeuralPairwiseRegressor(embedder, 2*_size, 2*_size, _layers, lr=1e-4)\n",
    "\n",
    "    # classic lightning training, inference\n",
    "    loader_kwargs = dict(batch_size=256, collate_fn=_collate_fn, persistent_workers=True, num_workers=1)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, **loader_kwargs)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, **loader_kwargs)\n",
    "    val_absolute_loader = torch.utils.data.DataLoader(val_absolute_dataset, **loader_kwargs)\n",
    "    predict_loader = torch.utils.data.DataLoader(test_dataset, **loader_kwargs)\n",
    "    early_stopping = EarlyStopping(monitor=\"validation/loss\", patience=10)\n",
    "    name = \"\".join(c if c.isalnum() else \"_\" for c in task_name)\n",
    "    model_checkpoint = ModelCheckpoint(dirpath=output_dir / name, monitor=\"validation/loss\")\n",
    "    logger = TensorBoardLogger(save_dir=output_dir, name=name, default_hp_metric=False)\n",
    "    trainer = lightning.Trainer(max_epochs=100, log_every_n_steps=1, callbacks=[early_stopping, model_checkpoint], logger=logger)\n",
    "    print(npr)\n",
    "    trainer.fit(npr, train_loader, val_loader)\n",
    "    npr = LearnedEmbeddingNeuralPairwiseRegressor.load_from_checkpoint(model_checkpoint.best_model_path)\n",
    "\n",
    "    # we use the predict function from nepare, which automatically maps difference-space predictions back to absolute space\n",
    "    y_pred, y_stdev = predict(npr, val_absolute_loader)\n",
    "\n",
    "    # checking our performance on the validation set\n",
    "    # leave in the scaled space so that the average is weighted equally among the targets\n",
    "    results_dict = evaluate_predictions(val_targets.flatten().numpy(), y_pred.flatten().numpy())\n",
    "    val_score.append((len(val_targets), results_dict[\"MAE\"]))\n",
    "    # now go back to correct scale\n",
    "    y_pred = inverse_standard_scale(y_pred, target_means, target_vars)\n",
    "    y_true = inverse_standard_scale(val_targets, target_means, target_vars)\n",
    "    print(f\"{task_name=}:\\n - {\"\\n - \".join([f'{name}: {score:.4f}' for name, score in evaluate_predictions(y_true.flatten().numpy(), y_pred.flatten().numpy()).items()])}\")\n",
    "\n",
    "    # finally predict on the test set, descale, and save them for later\n",
    "    y_pred, y_stdev = predict(npr, predict_loader)\n",
    "    y_pred = inverse_standard_scale(y_pred, target_means, target_vars)\n",
    "    predictions[task_name] = y_pred.flatten().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hope is that the below number roughly matches with the actual performance on the `polaris` leaderboard.\n",
    "I say _hope_ because the composition of the blind test set and my validation set will invariably be different, just hopefully not _so_ different that the validation set actually causes _bad_ early stopping (i.e. too early or too late)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Scaled Weighted Average MAE 0.3680\n"
     ]
    }
   ],
   "source": [
    "print(f\"Validation Scaled Weighted Average MAE {sum(n*s for n, s in val_score) / sum(n for n, _ in val_score):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This last block is commented out because it will fail (unless you are me) - you can replace the inputs with your own if you are submitting this for yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b273fedaf8154298aca6ce5fcaac4bd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[17:37:31] </span><span style=\"color: #008000; text-decoration-color: #008000\"> Success: Submitting competition predictions</span>                                               <a href=\"file:///home/jackson/neural-pairwise-regression/.venv/lib/python3.12/site-packages/polaris/utils/context.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">context.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/jackson/neural-pairwise-regression/.venv/lib/python3.12/site-packages/polaris/utils/context.py#53\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">53</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[17:37:31]\u001b[0m\u001b[2;36m \u001b[0m\u001b[32m Success: Submitting competition predictions\u001b[0m                                               \u001b]8;id=752469;file:///home/jackson/neural-pairwise-regression/.venv/lib/python3.12/site-packages/polaris/utils/context.py\u001b\\\u001b[2mcontext.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=564660;file:///home/jackson/neural-pairwise-regression/.venv/lib/python3.12/site-packages/polaris/utils/context.py#53\u001b\\\u001b[2m53\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "competition.submit_predictions(\n",
    "    predictions=predictions,\n",
    "    prediction_name=\"nepare\",\n",
    "    prediction_owner=\"jacksonburns\",\n",
    "    report_url=\"https://github.com/JacksonBurns/neural-pairwise-regression/blob/main/meta\",\n",
    "    github_url = \"https://github.com/JacksonBurns/neural-pairwise-regression/blob/main/notebooks/polaris_asap.ipynb\",\n",
    "    description = \"Neural Pairwise Regression with ChemProp + Mordred\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
