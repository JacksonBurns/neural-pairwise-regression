{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining ChemProp, `polaris`, and `nepare`\n",
    "\n",
    "This notebook demonstrates using ChemProp as a learnable embedding with Neural Pairwise Regression (via `nepare`) with the `polaris` benchmarking library.\n",
    "\n",
    "## Requirements\n",
    "Python 3.10+ (originally run on 3.12)\n",
    " - polaris-lib\n",
    " - pandas\n",
    " - rdkit\n",
    " - lightning\n",
    " - torch\n",
    " - ipywidgets\n",
    "\n",
    "You will also need to run `pip install .` in the repository's root directory to install `nepare`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `polaris` Setup\n",
    "\n",
    "After running `polaris login` on the command line, we can import everything (checking that the version is recent enough) and then download the benchmark data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polaris as po\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from packaging.version import Version\n",
    "assert Version(po.__version__) >= Version(\"0.11.6\"), \"test.as_dataframe does not work in earlier versions of Polaris, please upgrade\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`polaris` makes it really easy to run different benchmarks quickly - just change the name inside `load_benchmark` to try something else.\n",
    "I'm using this same notebook for a few different benchmarks, all from the Fang biogen ADME paper (https://pubs.acs.org/doi/abs/10.1021/acs.jcim.3c00160) which have been made conveniently available on `polaris`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# https://polarishub.io/benchmarks/polaris/adme-fang-rppb-1\n",
    "# benchmark = po.load_benchmark(\"polaris/adme-fang-RPPB-1\")\n",
    "# https://polarishub.io/benchmarks/polaris/adme-fang-solu-1\n",
    "benchmark = po.load_benchmark(\"polaris/adme-fang-SOLU-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = benchmark.get_train_test_split()\n",
    "test_df: pd.DataFrame = test.as_dataframe()\n",
    "train_df: pd.DataFrame = train.as_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll shuffle the data just for good measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.sample(frac=1.0, random_state=1701)  # shuffle the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn an Embedding with ChemProp\n",
    "ChemProp using Message Passing Graph Neural Networks to learn a molecular representation tailored for the problem at hand.\n",
    "We can 'plug it in' to `nepare` to take advantage of that, with the additional benefit for ChemProp that it will have more training data to learn its representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idx = 150  # use n for validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll first write a function that converts our SMILES into their ChemProp input (a `MolGraph`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import MolFromSmiles\n",
    "from chemprop.featurizers import MolGraphCache, SimpleMoleculeMolGraphFeaturizer\n",
    "\n",
    "def smiles2molgraphcache(smiles: list[str]):\n",
    "    mols = list(map(MolFromSmiles, smiles))\n",
    "    featurizer = SimpleMoleculeMolGraphFeaturizer()\n",
    "    mgc = MolGraphCache(mols, [None] * len(mols), [None] * len(mols), featurizer)\n",
    "    return mgc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mgc = smiles2molgraphcache(train_df[\"smiles\"][val_idx:])\n",
    "train_targets = train_df[\"LOG_SOLUBILITY\"][val_idx:].to_numpy()\n",
    "val_mgc = smiles2molgraphcache(train_df[\"smiles\"][:val_idx])\n",
    "val_targets = train_df[\"LOG_SOLUBILITY\"][:val_idx].to_numpy()\n",
    "test_mgc = smiles2molgraphcache(test_df[\"smiles\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nepare.data import PairwiseAugmentedDataset, PairwiseAnchoredDataset, PairwiseInferenceDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PairwiseAugmentedDataset(train_mgc, train_targets)\n",
    "val_dataset = PairwiseAnchoredDataset(train_mgc, train_targets, val_mgc, val_targets)\n",
    "test_dataset = PairwiseInferenceDataset(train_mgc, train_targets, test_mgc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to write a function to collate our `MolGraph`s and target values - ChemProp has a class for batches of `MolGraph` aptly named `BatchMolGraph`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "\n",
    "import torch\n",
    "from chemprop.data.molgraph import MolGraph\n",
    "from chemprop.data.collate import BatchMolGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _collate(batch: Iterable[tuple[MolGraph, MolGraph, float]]):\n",
    "    mgs_1, mgs_2, ys = zip(*batch)  #  now need to convert y back into a tensor\n",
    "    return BatchMolGraph(mgs_1), BatchMolGraph(mgs_2), torch.tensor(ys, dtype=torch.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=_collate)\n",
    "val_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, collate_fn=_collate)\n",
    "predict_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, collate_fn=_collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we just need to define a class to take our collated batches and convert them into their learned representations.\n",
    "This class can then be passed to the `nepare` class `LearnedEmbeddingNeuralPairwiseRegressor`, which will call our class on the two inputs for each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chemprop.conf import DEFAULT_HIDDEN_DIM\n",
    "from chemprop.nn.agg import MeanAggregation\n",
    "from chemprop.nn.message_passing import BondMessagePassing\n",
    "\n",
    "from nepare.nn import LearnedEmbeddingNeuralPairwiseRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChemPropEmbedder(torch.nn.Module):\n",
    "    def __init__(self, mp, agg):\n",
    "        super().__init__()\n",
    "        self.mp = mp\n",
    "        self.agg = agg\n",
    "\n",
    "    def forward(self, bmg):\n",
    "        H = self.mp(bmg)\n",
    "        Z = self.agg(H, bmg.batch)\n",
    "        return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = BondMessagePassing()\n",
    "agg = MeanAggregation()\n",
    "embedder = ChemPropEmbedder(mp, agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npr = LearnedEmbeddingNeuralPairwiseRegressor(embedder, DEFAULT_HIDDEN_DIM, 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Predicting\n",
    "\n",
    "From here on out we follow a very standard `lightning` training workflow - see `demo.ipynb` for a slightly more in-depth explanation of what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks.model_checkpoint import ModelCheckpoint\n",
    "\n",
    "from nepare.inference import predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor=\"validation/loss\", patience=3)\n",
    "model_checkpoint = ModelCheckpoint(monitor=\"validation/loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = lightning.Trainer(max_epochs=50, log_every_n_steps=1, callbacks=[early_stopping, model_checkpoint])\n",
    "trainer.fit(npr, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npr = LearnedEmbeddingNeuralPairwiseRegressor.load_from_checkpoint(model_checkpoint.best_model_path)  # reload best model based on early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, y_stdev = predict(npr, predict_loader, how=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = benchmark.evaluate(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.name = \"nepare\"\n",
    "results.description = \"Neural Pairwise Regression with Mordred(-community) Molecular Descriptors\"\n",
    "results.github_url = \"https://github.com/JacksonBurns/neural-pairwise-regression/blob/main/notebooks/polaris_chemprop_nepare.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This last line is commented out because it will fail (unless you are me) - you can replace the `owner` without your own name to upload your results (and also update the link, name, and description above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results.upload_to_hub(owner=\"jacksonburns\", access=\"public\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
