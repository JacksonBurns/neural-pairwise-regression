{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining ChemProp, `polaris`, and `nepare`\n",
    "\n",
    "This notebook demonstrates using ChemProp as a learnable embedding with Neural Pairwise Regression (via `nepare`) with the `polaris` benchmarking library.\n",
    "\n",
    "## Requirements\n",
    "Python 3.10+ (originally run on 3.12)\n",
    " - polaris-lib\n",
    " - pandas\n",
    " - fastprop\n",
    " - mordredcommunity\n",
    " - rdkit\n",
    " - lightning\n",
    " - torch\n",
    " - numpy\n",
    " - ipywidgets\n",
    " - chemprop 2.1 or newer\n",
    "\n",
    "You will also need to run `pip install .` in the repository's root directory to install `nepare`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `polaris` Setup\n",
    "\n",
    "After running `polaris login` on the command line, we can import everything (checking that the version is recent enough) and then download the benchmark data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polaris as po\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from packaging.version import Version\n",
    "assert Version(po.__version__) >= Version(\"0.11.6\"), \"test.as_dataframe does not work in earlier versions of Polaris, please upgrade\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`polaris` makes it really easy to run different benchmarks quickly - just change the name inside `load_benchmark` to try something else.\n",
    "I'm using this same notebook for a few different benchmarks, all from the Fang biogen ADME paper (https://pubs.acs.org/doi/abs/10.1021/acs.jcim.3c00160) which have been made conveniently available on `polaris`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# https://polarishub.io/benchmarks/polaris/adme-fang-rppb-1\n",
    "# benchmark = po.load_benchmark(\"polaris/adme-fang-RPPB-1\")\n",
    "# https://polarishub.io/benchmarks/polaris/adme-fang-solu-1\n",
    "benchmark = po.load_benchmark(\"polaris/adme-fang-SOLU-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = benchmark.get_train_test_split()\n",
    "test_df: pd.DataFrame = test.as_dataframe()\n",
    "train_df: pd.DataFrame = train.as_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll shuffle the data just for good measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.sample(frac=1.0, random_state=1701)  # shuffle the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>LOG_SOLUBILITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>O=C(CCc1ccco1)Nc1ccccc1OC(F)F</td>\n",
       "      <td>1.649627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>CCCN(Cc1ccccc1)C(=O)CC1(N)CCC1</td>\n",
       "      <td>1.751356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>Cc1cc(C)c(S(=O)(=O)Nc2ccc(N(C)C)cc2)c(C)c1-n1c...</td>\n",
       "      <td>0.436163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>CCOc1cccc(CNCCc2c[nH]c3ccccc23)c1</td>\n",
       "      <td>1.863263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>NCC(=O)Nc1ccc(-n2nc(C(F)(F)F)cc2-c2ccc3c(ccc4c...</td>\n",
       "      <td>-0.602060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>CCn1ccc2cc(C(=O)N3CCN(c4ccc(C)cc4)C(=O)C3)ccc21</td>\n",
       "      <td>1.660201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518</th>\n",
       "      <td>CN(C)[C@@H]1CN(C(=O)CCn2cnc3ccccc32)C[C@H]1O</td>\n",
       "      <td>2.179264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>Nc1ncc(-c2cccc(C(F)(F)F)c2)c(C2CCCCN2C(=O)c2cc...</td>\n",
       "      <td>1.399674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>COc1cccc(CN(C)c2ncnc3c2CN(C)CC3)c1</td>\n",
       "      <td>1.761402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>CN(Cc1cnccn1)C(=O)c1cc(-c2ccc(F)cc2)on1</td>\n",
       "      <td>1.203848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1578 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 smiles  LOG_SOLUBILITY\n",
       "474                       O=C(CCc1ccco1)Nc1ccccc1OC(F)F        1.649627\n",
       "913                      CCCN(Cc1ccccc1)C(=O)CC1(N)CCC1        1.751356\n",
       "1268  Cc1cc(C)c(S(=O)(=O)Nc2ccc(N(C)C)cc2)c(C)c1-n1c...        0.436163\n",
       "618                   CCOc1cccc(CNCCc2c[nH]c3ccccc23)c1        1.863263\n",
       "1334  NCC(=O)Nc1ccc(-n2nc(C(F)(F)F)cc2-c2ccc3c(ccc4c...       -0.602060\n",
       "...                                                 ...             ...\n",
       "1475    CCn1ccc2cc(C(=O)N3CCN(c4ccc(C)cc4)C(=O)C3)ccc21        1.660201\n",
       "1518       CN(C)[C@@H]1CN(C(=O)CCn2cnc3ccccc32)C[C@H]1O        2.179264\n",
       "1118  Nc1ncc(-c2cccc(C(F)(F)F)c2)c(C2CCCCN2C(=O)c2cc...        1.399674\n",
       "1540                 COc1cccc(CN(C)c2ncnc3c2CN(C)CC3)c1        1.761402\n",
       "174             CN(Cc1cnccn1)C(=O)c1cc(-c2ccc(F)cc2)on1        1.203848\n",
       "\n",
       "[1578 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn an Embedding with ChemProp\n",
    "ChemProp using Message Passing Graph Neural Networks to learn a molecular representation tailored for the problem at hand.\n",
    "We can 'plug it in' to `nepare` to take advantage of that, with the additional benefit for ChemProp that it will have more training data to learn its representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idx = 150  # use n for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from chemprop import data, featurizers, models, nn\n",
    "# import torch\n",
    "# import numpy as np\n",
    "\n",
    "# from nepare.data import PairwiseAugmentedDataset, PairwiseAnchoredDataset, PairwiseInferenceDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_mols = list(map(MolFromSmiles, train_df[\"smiles\"][val_idx:]))\n",
    "# train_targets = torch.tensor(train_df[\"LOG_SOLUBILITY\"][val_idx:].to_numpy(), dtype=torch.float32)\n",
    "# val_mols = list(map(MolFromSmiles, train_df[\"smiles\"][:val_idx]))\n",
    "# val_targets = torch.tensor(train_df[\"LOG_SOLUBILITY\"][:val_idx].to_numpy(), dtype=torch.float32)\n",
    "# test_mols = list(map(MolFromSmiles, test_df[\"smiles\"]))\n",
    "# train_dataset = PairwiseAugmentedDataset(train_mols, train_targets)\n",
    "# train_dataset.downsample_(n=100_000)\n",
    "# val_dataset = PairwiseAnchoredDataset(train_mols, train_targets, val_mols, val_targets)\n",
    "# test_dataset = PairwiseInferenceDataset(train_mols, train_targets, test_mols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by converting our SMILES into RDKit mols, and then convert them into their corresponding ChemProp features.\n",
    "\n",
    "TODO: refactor this into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import MolFromSmiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mols = list(map(MolFromSmiles, train_df[\"smiles\"][val_idx:]))\n",
    "val_mols = list(map(MolFromSmiles, train_df[\"smiles\"][:val_idx]))\n",
    "test_mols = list(map(MolFromSmiles, test_df[\"smiles\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chemprop.featurizers import MolGraphCache, SimpleMoleculeMolGraphFeaturizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = SimpleMoleculeMolGraphFeaturizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mgc = MolGraphCache(train_mols, [None] * len(train_mols), [None] * len(train_mols), featurizer)\n",
    "val_mgc = MolGraphCache(val_mols, [None] * len(val_mols), [None] * len(val_mols), featurizer)\n",
    "test_mgc = MolGraphCache(test_mols, [None] * len(train_mols), [None] * len(train_mols), featurizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nepare.data import PairwiseAugmentedDataset, PairwiseAnchoredDataset, PairwiseInferenceDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PairwiseAugmentedDataset(mgc, train_df[\"LOG_SOLUBILITY\"][val_idx:].to_numpy())\n",
    "val_dataset = PairwiseAnchoredDataset(mgc, train_df[\"LOG_SOLUBILITY\"][val_idx:].to_numpy())\n",
    "test_dataset = PairwiseInferenceDataset(mgc, train_df[\"LOG_SOLUBILITY\"][val_idx:].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chemprop.data.molgraph import MolGraph\n",
    "\n",
    "from chemprop.data.collate import BatchMolGraph\n",
    "\n",
    "from typing import Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _collate(batch: Iterable[tuple[MolGraph, MolGraph, float]]):\n",
    "    mgs_1, mgs_2, ys = zip(*batch)  # may need to cast back to a tensor here (y especially)\n",
    "    return BatchMolGraph(mgs_1), BatchMolGraph(mgs_2), torch.tensor(ys, dtype=torch.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make a list of molgraph objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks.model_checkpoint import ModelCheckpoint\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Pairwise Regression\n",
    "\n",
    "`nepare` provides a number of convenience classes than handle training, validation, and testing augmentation automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nepare.nn import NeuralPairwiseRegressor as NPR\n",
    "from nepare.data import PairwiseAugmentedDataset, PairwiseAnchoredDataset, PairwiseInferenceDataset\n",
    "from nepare.inference import predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chemprop.data import BatchMolGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64)\n",
    "predict_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nt = torch.nested.nested_tensor([[1,2],[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nt.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Learnable Embedding Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nepare.nn import LearnedEmbeddingNeuralPairwiseRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PassThroughPredictor(nn.Predictor):\n",
    "    def forward(self, Z):\n",
    "        return Z\n",
    "\n",
    "    def train_step(self, Z):\n",
    "        return Z\n",
    "\n",
    "    def encode(self, Z, i: int):\n",
    "        return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chemprop.conf import DEFAULT_HIDDEN_DIM\n",
    "from chemprop.models import MPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chemprop.nn.agg import MeanAggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChemPropEmbedder(torch.nn.Module):\n",
    "    def __init__(self, mp, agg):\n",
    "        super().__init__()\n",
    "        self.mp = mp\n",
    "        self.agg = agg\n",
    "\n",
    "    def forward(self, bmg):\n",
    "        H = self.mp(bmg)\n",
    "        Z = self.agg(H, bmg.batch)\n",
    "        return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = nn.BondMessagePassing()\n",
    "agg = nn.MeanAggregation()\n",
    "embedder = ChemPropEmbedder(mp, agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npr = LearnedEmbeddingNeuralPairwiseRegressor(embedder, DEFAULT_HIDDEN_DIM, 100, 2)\n",
    "early_stopping = EarlyStopping(monitor=\"validation/loss\", patience=10)\n",
    "model_checkpoint = ModelCheckpoint(monitor=\"validation/loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# must be a learnable module that takes two inputs of some arbitrary type and generates a vector representation\n",
    "\n",
    "ptp = PassThroughPredictor()\n",
    "\n",
    "embedder = torch.nn.Sequential(mp, agg)\n",
    "# embedder = MPNN(mp, agg, ptp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These networks can overfit very quickly, so we will use `EarlyStopping` to stop training once we start overfitting and then reset the network to to _just before_ it overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npr = LearnedEmbeddingNeuralPairwiseRegressor(embedder, DEFAULT_HIDDEN_DIM, 100, 2)\n",
    "early_stopping = EarlyStopping(monitor=\"validation/loss\", patience=10)\n",
    "model_checkpoint = ModelCheckpoint(monitor=\"validation/loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = lightning.Trainer(max_epochs=50, log_every_n_steps=1, callbacks=[early_stopping, model_checkpoint])\n",
    "trainer.fit(npr, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "npr = NPR.load_from_checkpoint(model_checkpoint.best_model_path)  # reload best model based on early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, y_stdev = predict(npr, predict_loader, how=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we had re-scaled the target, we would have to undo that scaling like this:\n",
    "\n",
    "```python\n",
    "y_pred = inverse_standard_scale(torch.tensor(y_pred), target_means, target_vars)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, Results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = benchmark.evaluate(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.name = \"nepare\"\n",
    "results.description = \"Neural Pairwise Regression with Mordred(-community) Molecular Descriptors\"\n",
    "results.github_url = \"https://github.com/JacksonBurns/neural-pairwise-regression/blob/main/notebooks/polaris_adme.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As of writing, this method lands at third on the leaderboard just barely losing out to a couple 1 _billion_ parameter MPNN-based foundation models.\n",
    "We've achieved pretty similar performance (without any tuning!) in just a few minutes - pretty good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This last line is commented out because it will fail (unless you are me) - you can replace the `owner` without your own name to upload your results (and also update the link, name, and description above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.upload_to_hub(owner=\"jacksonburns\", access=\"public\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
