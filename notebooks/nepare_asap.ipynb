{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining ChemProp, `polaris`, and `nepare`\n",
    "\n",
    "This notebook demonstrates using ChemProp as a learnable embedding with Neural Pairwise Regression (via `nepare`) with the `polaris` benchmarking library.\n",
    "\n",
    "## Requirements\n",
    "Python 3.10+ (originally run on 3.12)\n",
    " - polaris-lib\n",
    " - pandas\n",
    " - rdkit\n",
    " - lightning\n",
    " - torch\n",
    " - ipywidgets\n",
    "\n",
    "You will also need to run `pip install .` in the repository's root directory to install `nepare`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `polaris` Setup\n",
    "\n",
    "After running `polaris login` on the command line, we can import everything (checking that the version is recent enough) and then download the benchmark data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polaris as po\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from packaging.version import Version\n",
    "assert Version(po.__version__) >= Version(\"0.11.6\"), \"test.as_dataframe does not work in earlier versions of Polaris, please upgrade\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`polaris` makes it really easy to run different benchmarks quickly - just change the name inside `load_benchmark` to try something else.\n",
    "I'm using this same notebook for a few different benchmarks, all from the Fang biogen ADME paper (https://pubs.acs.org/doi/abs/10.1021/acs.jcim.3c00160) which have been made conveniently available on `polaris`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "competition = po.load_competition(\"asap-discovery/antiviral-potency-2025\")\n",
    "# or\n",
    "# competition = po.load_competition(\"asap-discovery/antiviral-admet-2025\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = competition.get_train_test_split()\n",
    "test_df: pd.DataFrame = test.as_dataframe()\n",
    "train_df: pd.DataFrame = train.as_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll shuffle the data just for good measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.sample(frac=1.0, random_state=1701)  # shuffle the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CXSMILES</th>\n",
       "      <th>pIC50 (MERS-CoV Mpro)</th>\n",
       "      <th>pIC50 (SARS-CoV-2 Mpro)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>CNC(=O)CN1C[C@]2(C(=O)N(C3=CN=CC4=CC=CC=C34)C[...</td>\n",
       "      <td>4.09</td>\n",
       "      <td>5.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>CNC(=O)CN1C[C@]2(C(=O)N(C3=CN=CC4=CC=CC=C34)C[...</td>\n",
       "      <td>4.15</td>\n",
       "      <td>5.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>C[C@H]1CN(C2=CN=CC3=CC=CC=C23)C(=O)[C@@]12CN(C...</td>\n",
       "      <td>5.50</td>\n",
       "      <td>6.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>O=C(CN1CC2=CC=C(Cl)C=C2[C@H](C(=O)NC2=CN=CC3=C...</td>\n",
       "      <td>5.05</td>\n",
       "      <td>6.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>O=C(CC1=CC(F)=CN=C1)NC1=CN=CC2=CC=CC=C12</td>\n",
       "      <td>4.18</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>CC1=NC=C(C2=CC=CC(Cl)=C2)C(=O)N1C1=CN=CC2=CC=C...</td>\n",
       "      <td>4.91</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>O=C(CC1=CN=CC2=CC=CC=C12)N1CC[C@H]2C[C@H]2C1 |...</td>\n",
       "      <td>4.62</td>\n",
       "      <td>4.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>O=C(CC1=CN=CC2=CC=CC=C12)N1CCC(F)(C2=CC=CC=C2)CC1</td>\n",
       "      <td>3.84</td>\n",
       "      <td>4.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>O=C(CC1=CN=CC2=CC=CC=C12)N1CC[C@H](CC2=CC=CC(C...</td>\n",
       "      <td>4.04</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>O=C(NC1=CN=CC2=CC=CC=C12)C(F)(F)C1=CC(F)=CC(F)=C1</td>\n",
       "      <td>4.16</td>\n",
       "      <td>5.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1031 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              CXSMILES  pIC50 (MERS-CoV Mpro)  \\\n",
       "103  CNC(=O)CN1C[C@]2(C(=O)N(C3=CN=CC4=CC=CC=C34)C[...                   4.09   \n",
       "200  CNC(=O)CN1C[C@]2(C(=O)N(C3=CN=CC4=CC=CC=C34)C[...                   4.15   \n",
       "605  C[C@H]1CN(C2=CN=CC3=CC=CC=C23)C(=O)[C@@]12CN(C...                   5.50   \n",
       "430  O=C(CN1CC2=CC=C(Cl)C=C2[C@H](C(=O)NC2=CN=CC3=C...                   5.05   \n",
       "169           O=C(CC1=CC(F)=CN=C1)NC1=CN=CC2=CC=CC=C12                   4.18   \n",
       "..                                                 ...                    ...   \n",
       "280  CC1=NC=C(C2=CC=CC(Cl)=C2)C(=O)N1C1=CN=CC2=CC=C...                   4.91   \n",
       "852  O=C(CC1=CN=CC2=CC=CC=C12)N1CC[C@H]2C[C@H]2C1 |...                   4.62   \n",
       "526  O=C(CC1=CN=CC2=CC=CC=C12)N1CCC(F)(C2=CC=CC=C2)CC1                   3.84   \n",
       "528  O=C(CC1=CN=CC2=CC=CC=C12)N1CC[C@H](CC2=CC=CC(C...                   4.04   \n",
       "174  O=C(NC1=CN=CC2=CC=CC=C12)C(F)(F)C1=CC(F)=CC(F)=C1                   4.16   \n",
       "\n",
       "     pIC50 (SARS-CoV-2 Mpro)  \n",
       "103                     5.20  \n",
       "200                     5.27  \n",
       "605                     6.44  \n",
       "430                     6.14  \n",
       "169                     5.33  \n",
       "..                       ...  \n",
       "280                     4.80  \n",
       "852                     4.55  \n",
       "526                     4.63  \n",
       "528                     4.98  \n",
       "174                     5.53  \n",
       "\n",
       "[1031 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn an Embedding with ChemProp\n",
    "ChemProp using Message Passing Graph Neural Networks to learn a molecular representation tailored for the problem at hand.\n",
    "We can 'plug it in' to `nepare` to take advantage of that, with the additional benefit for ChemProp that it will have more training data to learn its representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idx = int(len(train_df) * 0.15)  # use n for validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll first write a function that converts our SMILES into their ChemProp input (a `MolGraph`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import MolFromSmiles\n",
    "from chemprop.featurizers import MolGraphCache, SimpleMoleculeMolGraphFeaturizer\n",
    "\n",
    "def smiles2molgraphcache(smiles: list[str]):\n",
    "    mols = list(map(MolFromSmiles, smiles))\n",
    "    featurizer = SimpleMoleculeMolGraphFeaturizer()\n",
    "    mgc = MolGraphCache(mols, [None] * len(mols), [None] * len(mols), featurizer)\n",
    "    return mgc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mgc = smiles2molgraphcache(train_df[\"CXSMILES\"][val_idx:])\n",
    "train_targets = torch.tensor(train_df[list(competition.target_cols)][val_idx:].to_numpy(), dtype=torch.float32)\n",
    "val_mgc = smiles2molgraphcache(train_df[\"CXSMILES\"][:val_idx])\n",
    "val_targets = torch.tensor(train_df[list(competition.target_cols)][:val_idx].to_numpy(), dtype=torch.float32)\n",
    "test_mgc = smiles2molgraphcache(test_df[\"CXSMILES\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastprop.data import standard_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets, target_means, target_vars = standard_scale(train_targets)\n",
    "val_targets = standard_scale(val_targets, target_means, target_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nepare.data import PairwiseAugmentedDataset, PairwiseAnchoredDataset, PairwiseInferenceDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PairwiseAugmentedDataset(train_mgc, train_targets)\n",
    "val_dataset = PairwiseAnchoredDataset(train_mgc, train_targets, val_mgc, val_targets)\n",
    "test_dataset = PairwiseInferenceDataset(train_mgc, train_targets, test_mgc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to write a function to collate our `MolGraph`s and target values - ChemProp has a class for batches of `MolGraph` aptly named `BatchMolGraph`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from chemprop.data.molgraph import MolGraph\n",
    "from chemprop.data.collate import BatchMolGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _collate(batch: Iterable[tuple[MolGraph, MolGraph, float]]):\n",
    "    mgs_1, mgs_2, ys = zip(*batch)  #  now need to convert y back into a tensor\n",
    "    return BatchMolGraph(mgs_1), BatchMolGraph(mgs_2), torch.tensor(np.array(ys), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=_collate)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=512, collate_fn=_collate)\n",
    "predict_loader = torch.utils.data.DataLoader(test_dataset, batch_size=512, collate_fn=_collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we just need to define a class to take our collated batches and convert them into their learned representations.\n",
    "This class can then be passed to the `nepare` class `LearnedEmbeddingNeuralPairwiseRegressor`, which will call our class on the two inputs for each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chemprop.conf import DEFAULT_HIDDEN_DIM\n",
    "from chemprop.nn.agg import MeanAggregation\n",
    "from chemprop.nn.message_passing import BondMessagePassing\n",
    "\n",
    "from nepare.nn import LearnedEmbeddingNeuralPairwiseRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChemPropEmbedder(torch.nn.Module):\n",
    "    def __init__(self, mp, agg):\n",
    "        super().__init__()\n",
    "        self.mp = mp\n",
    "        self.agg = agg\n",
    "\n",
    "    def forward(self, bmg):\n",
    "        H = self.mp(bmg)\n",
    "        Z = self.agg(H, bmg.batch)\n",
    "        return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = BondMessagePassing()\n",
    "agg = MeanAggregation()\n",
    "embedder = ChemPropEmbedder(mp, agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jackson/neural-pairwise-regression/.venv/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'embedding_module' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['embedding_module'])`.\n"
     ]
    }
   ],
   "source": [
    "npr = LearnedEmbeddingNeuralPairwiseRegressor(embedder, DEFAULT_HIDDEN_DIM, 100, 2, n_targets=len(competition.target_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Predicting\n",
    "\n",
    "From here on out we follow a very standard `lightning` training workflow - see `demo.ipynb` for a slightly more in-depth explanation of what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks.model_checkpoint import ModelCheckpoint\n",
    "\n",
    "from nepare.inference import predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor=\"validation/loss\", patience=3)\n",
    "model_checkpoint = ModelCheckpoint(monitor=\"validation/loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = lightning.Trainer(max_epochs=50, log_every_n_steps=1, callbacks=[early_stopping, model_checkpoint])\n",
    "trainer.fit(npr, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jackson/neural-pairwise-regression/.venv/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'embedding_module' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['embedding_module'])`.\n"
     ]
    }
   ],
   "source": [
    "npr = LearnedEmbeddingNeuralPairwiseRegressor.load_from_checkpoint(\"/home/jackson/neural-pairwise-regression/notebooks/lightning_logs/version_0/checkpoints/epoch=1-step=24036.ckpt\")  # reload best model based on early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cebddefbf9a24578aabd402776ddf480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred, y_stdev = predict(npr, predict_loader, how=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastprop.data import inverse_standard_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_131504/3008948553.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_pred = inverse_standard_scale(torch.tensor(y_pred), target_means, target_vars)\n"
     ]
    }
   ],
   "source": [
    "y_pred = inverse_standard_scale(torch.tensor(y_pred), target_means, target_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {name: y_pred[:, i].tolist() for i, name in enumerate(competition.target_cols)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This last block is commented out because it will fail (unless you are me) - you can replace the inputs with your own if you are submitting this for yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34bbb002285d4451a7d8b2af6d5bc174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[00:50:37] </span><span style=\"color: #008000; text-decoration-color: #008000\"> Success: Submitting competition predictions</span>                                               <a href=\"file:///home/jackson/neural-pairwise-regression/.venv/lib/python3.12/site-packages/polaris/utils/context.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">context.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/jackson/neural-pairwise-regression/.venv/lib/python3.12/site-packages/polaris/utils/context.py#53\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">53</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[00:50:37]\u001b[0m\u001b[2;36m \u001b[0m\u001b[32m Success: Submitting competition predictions\u001b[0m                                               \u001b]8;id=971288;file:///home/jackson/neural-pairwise-regression/.venv/lib/python3.12/site-packages/polaris/utils/context.py\u001b\\\u001b[2mcontext.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=763700;file:///home/jackson/neural-pairwise-regression/.venv/lib/python3.12/site-packages/polaris/utils/context.py#53\u001b\\\u001b[2m53\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "competition.submit_predictions(\n",
    "    predictions=predictions,\n",
    "    prediction_name=\"nepare_chemprop\",\n",
    "    prediction_owner=\"jacksonburns\",\n",
    "    report_url=\"https://github.com/JacksonBurns/neural-pairwise-regression/blob/main/meta\",\n",
    "    github_url = \"https://github.com/JacksonBurns/neural-pairwise-regression/blob/main/notebooks/nepare_asap.ipynb\",\n",
    "    description = \"Neural Pairwise Regression with ChemProp as a learnable embedding\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
